Hello World:

	RabbitMQ is a post box, a post office and a letter carrier at once. (exchange, storage, queue).

	Messages are binary blobs of data.

	Producing means sending messages. It's done by producer apps.

	Queue is the post box in RabbitMQ. All messages are stored inside a queue. It's message buffer. Many producers can send messages to one queue, and many consumers can try to receive data from one queue.

	Consuming means receiving a messages. It's done by consumer apps.

	An application can be both a producer and consumer, too.

	Sending:
		The connection abstracts the socket connection, and takes care of protocol version negotiation and authentication and so on for us.

		A channel, which is where most of the API for getting things done resides.

		To send, we must declare a queue for us to send to; then we can publish a message to the queue:

			var factory = new ConnectionFactory { HostName = "localhost" };
			using var connection = factory.CreateConnection();
			using var channel = connection.CreateModel();

			channel.QueueDeclare(queue: "hello",
			                     durable: false,
			                     exclusive: false,
			                     autoDelete: false,
			                     arguments: null);

			const string message = "Hello World!";
			var body = Encoding.UTF8.GetBytes(message);

			channel.BasicPublish(exchange: string.Empty,
			                     routingKey: "hello",
			                     basicProperties: null,
			                     body: body);

		Declaring a queue is idempotent - it will only be created if it doesn't exist already. The message content is a byte array, so you can encode whatever you like there.

		When the code above finishes running, the channel and the connection will be disposed.

	Receiving:
		So unlike the publisher which publishes a single message, we'll keep the consumer running continuously to listen for messages and print them out.

		Setting up is the same as the publisher; we open a connection and a channel, and declare the queue from which we're going to consume.

		Note that we declare the queue here as well. Because we might start the consumer before the publisher, we want to make sure the queue exists before we try to consume messages from it.

			var factory = new ConnectionFactory { HostName = "localhost" };
			using var connection = factory.CreateConnection();
			using var channel = connection.CreateModel();

			channel.QueueDeclare(queue: "hello",
			                     durable: false,
			                     exclusive: false,
			                     autoDelete: false,
			                     arguments: null);

			Console.WriteLine(" [*] Waiting for messages.");

			var consumer = new EventingBasicConsumer(channel);
			consumer.Received += (model, ea) =>
			{
			    var body = ea.Body.ToArray();
			    var message = Encoding.UTF8.GetString(body);
			    Console.WriteLine($" [x] Received {message}");
			};
			channel.BasicConsume(queue: "hello",
			                     autoAck: true,
			                     consumer: consumer);

Work Queues (Distributing tasks among workers - the competing consumers pattern):
	The main idea behind Work Queues (aka: Task Queues) is to avoid doing a resource-intensive task immediately and having to wait for it to complete. Instead we schedule the task to be done later. We encapsulate a task as a message and send it to a queue. A worker process running in the background will pop the tasks and eventually execute the job. When you run many workers the tasks will be shared between them.

	This concept is especially useful in web applications where it's impossible to handle a complex task during a short HTTP request window.

	Round-robin dispatching:
		One of the advantages of using a Task Queue is the ability to easily parallelise work. If we are building up a backlog of work, we can just add more workers and that way, scale easily.

		First, let's try to run two Worker instances at the same time. They will both get messages from the queue, but how exactly?

		By default, RabbitMQ will send each message to the next consumer, in sequence. On average every consumer will get the same number of messages. This way of distributing messages is called round-robin.

	Message ACK:
		Doing a task can take a few seconds. You may wonder what happens if one of the consumers starts a long task and dies with it only partly done. With our current code, once RabbitMQ delivers a message to the consumer it immediately marks it for deletion. In this case, if you terminate a worker we will lose the message it was just processing. We'll also lose all the messages that were dispatched to this particular worker but were not yet handled.

		But we don't want to lose any tasks. If a worker dies, we'd like the task to be delivered to another worker.

		The timeout for ACK is by default 30 minutes.

		Manual message acknowledgments are turned on by default. In previous examples we explicitly turned them off by setting the autoAck ("automatic acknowledgement mode") parameter to true. It's time to remove this flag and manually send a proper acknowledgment from the worker, once we're done with a task.

			Console.WriteLine(" [x] Done");

	    	// here channel could also be accessed as ((EventingBasicConsumer)sender).Model
	    	channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false);

			channel.BasicConsume(queue: "hello",
	                     autoAck: false,
	                     consumer: consumer);

	    Using this code, you can ensure that even if you terminate a worker node using CTRL+C while it was processing a message, nothing is lost. Soon after the worker node is terminated, all unacknowledged messages will be redelivered.

		Acknowledgement must be sent on the same channel that received the delivery. Attempts to acknowledge using a different channel will result in a channel-level protocol exception.

	Message Durability:
		We have learned how to make sure that even if the consumer dies, the task isn't lost. But our tasks will still be lost if RabbitMQ server stops.

		When RabbitMQ quits or crashes it will forget the queues and messages unless you tell it not to. Two things are required to make sure that messages aren't lost: we need to mark both the queue and messages as durable.

			channel.QueueDeclare(queue: "hello",
                     durable: true,
                     exclusive: false,
                     autoDelete: false,
                     arguments: null);

        * RabbitMQ doesn't allow you to redefine an existing queue with different parameters and will return an error to any program that tries to do that.

        At this point we're sure that the task_queue queue won't be lost even if RabbitMQ restarts. Now we need to mark our messages as persistent.

        Set IBasicProperties.Persistent to true:

        	var properties = channel.CreateBasicProperties();
			properties.Persistent = true;

		* Marking messages as persistent doesn't fully guarantee that a message won't be lost. Although it tells RabbitMQ to save the message to disk, there is still a short time window when RabbitMQ has accepted a message and hasn't saved it yet. Also, RabbitMQ doesn't do fsync(2) for every message -- it may be just saved to cache and not really written to the disk. The persistence guarantees aren't strong, but it's more than enough for our simple task queue. If you need a stronger guarantee then you can use publisher confirms.

	Fair Dispatch:
		You might have noticed that the dispatching still doesn't work exactly as we want. For example in a situation with two workers, when all odd messages are heavy and even messages are light, one worker will be constantly busy and the other one will do hardly any work. Well, RabbitMQ doesn't know anything about that and will still dispatch messages evenly.

		This happens because RabbitMQ just dispatches a message when the message enters the queue. It doesn't look at the number of unacknowledged messages for a consumer. It just blindly dispatches every n-th message to the n-th consumer.

		In order to change this behavior we can use the BasicQos method with the prefetchCount = 1 setting. This tells RabbitMQ not to give more than one message to a worker at a time. Or, in other words, don't dispatch a new message to a worker until it has processed and acknowledged the previous one. Instead, it will dispatch it to the next worker that is not still busy.

			channel.QueueDeclare(queue: "task_queue",
                     durable: true,
                     exclusive: false,
                     autoDelete: false,
                     arguments: null);

			channel.BasicQos(prefetchSize: 0, prefetchCount: 1, global: false);

		* If all the workers are busy, your queue can fill up. You will want to keep an eye on that, and maybe add more workers, or have some other strategy.

Publish/Subscribe (Sending messages to many consumers at once via Fanout):
	We created a work queue. The assumption behind a work queue is that each task is delivered to exactly one worker. In this part we'll do something completely different -- we'll deliver a message to multiple consumers. This pattern is known as "publish/subscribe".

	So, we will implement the broadcast mechanism.

	Exchanges:
		* Queue is just a byffer that stores messages.

		The core idea in the messaging model in RabbitMQ is that the producer never sends any messages directly to a queue. Actually, quite often the producer doesn't even know if a message will be delivered to any queue at all.

		Instead, the producer can only send messages to an exchange. An exchange is a very simple thing. On one side it receives messages from producers and the other side it pushes them to queues. The exchange must know exactly what to do with a message it receives. Should it be appended to a particular queue? Should it be appended to many queues? Or should it get discarded. The rules for that are defined by the exchange type.

		There are a few exchange types available: direct, topic, headers and fanout.

			channel.ExchangeDeclare("logs", ExchangeType.Fanout);

		!!! The fanout exchange is very simple. As you can probably guess from the name, it just broadcasts all the messages it receives to all the queues it knows.

		* In previous parts of the tutorial we knew nothing about exchanges, but still were able to send messages to queues. That was possible because we were using a default exchange, which we identify by the empty string ("").

		* The first parameter is the name of the exchange. The empty string denotes the default or nameless exchange: messages are routed to the queue with the name specified by routingKey, if it exists.

	Temporary queues:
		As you may remember previously we were using queues that had specific names (remember hello and task_queue?). Being able to name a queue was crucial for us -- we needed to point the workers to the same queue. Giving a queue a name is important when you want to share the queue between producers and consumers.

		But that's not the case for our logger. We want to hear about all log messages, not just a subset of them. We're also interested only in currently flowing messages not in the old ones. To solve that we need two things.

		Firstly, whenever we connect to Rabbit we need a fresh, empty queue. To do this we could create a queue with a random name, or, even better - let the server choose a random queue name for us.

		Secondly, once we disconnect the consumer the queue should be automatically deleted.

		In the .NET client, when we supply no parameters to QueueDeclare() we create a non-durable, exclusive, autodelete queue with a generated name.

	Bindings:
		We need to tell the exchange to send messages to our queue. That relationship between exchange and a queue is called a binding.

			channel.QueueBind(queue: queueName,
                  exchange: "logs",
                  routingKey: string.Empty);

        From now on the logs exchange will append messages to our queue.

        The producer program, which emits log messages, doesn't look much different from the previous tutorial. The most important change is that we now want to publish messages to our logs exchange instead of the nameless one. We need to supply a routingKey when sending, but its value is ignored for fanout exchanges.

        The messages will be lost if no queue is bound to the exchange yet, but that's okay for us; if no consumer is listening yet we can safely discard the message.

        	// declare a server-named queue
			var queueName = channel.QueueDeclare().QueueName;
			channel.QueueBind(queue: queueName,
			                  exchange: "logs",
			                  routingKey: string.Empty);

		We can check existing bindings in rabbitmqctl:
			rabbitmqctl list_bindings

Routing (Receiving messages selectively - via Direct and setting proper bindings based on routing key - message routingKey==bindingRoutingKey):
	We're going to add a feature to it - we're going to make it possible to subscribe only to a subset of the messages. For example, we will be able to direct only critical error messages to the log file (to save disk space), while still being able to print all of the log messages on the console.

	Bindings:
		A binding is a relationship between an exchange and a queue. This can be simply read as: the queue is interested in messages from this exchange.

			channel.QueueBind(queue: queueName,
                  exchange: "logs",
                  routingKey: string.Empty);

    	Bindings can take an extra routingKey parameter. To avoid the confusion with a BasicPublish parameter we're going to call it a binding key. This is how we could create a binding with a key:

    		channel.QueueBind(queue: queueName,
                  exchange: "direct_logs",
                  routingKey: "black");

        !!! The meaning of a binding key depends on the exchange type. The fanout exchanges, which we used previously, simply ignored its value.

    Direct exchange:
    	Our logging system from the previous tutorial broadcasts all messages to all consumers. We want to extend that to allow filtering messages based on their severity. For example we may want the script which is writing log messages to the disk to only receive critical errors, and not waste disk space on warning or info log messages.

		We were using a fanout exchange, which doesn't give us much flexibility - it's only capable of mindless broadcasting.

		We will use a direct exchange instead. The routing algorithm behind a direct exchange is simple - a message goes to the queues whose binding key exactly matches the routing key of the message.

		In this setup, we can see the direct exchange X with two queues bound to it. The first queue is bound with binding key orange, and the second has two bindings, one with binding key black and the other one with green.

		In such a setup a message published to the exchange with a routing key orange will be routed to queue Q1. Messages with a routing key of black or green will go to Q2. All other messages will be discarded.

			channel.ExchangeDeclare(exchange: "direct_logs", type: ExchangeType.Direct);

			var body = Encoding.UTF8.GetBytes(message);
			channel.BasicPublish(exchange: "direct_logs",
			                     routingKey: severity,
			                     basicProperties: null,
			                     body: body);

		To simplify things we will assume that 'severity' can be one of 'info', 'warning', 'error'.

		Receiving messages will work just like in the previous tutorial, with one exception - we're going to create a new binding for each severity we're interested in.

Topics (receiving messages based on a pattern (topics)):
	Using the direct exchange improved our system, it still has limitations - it can't do routing based on multiple criteria.

	In our logging system we might want to subscribe to not only logs based on severity, but also based on the source which emitted the log. You might know this concept from the syslog unix tool, which routes logs based on both severity (info/warn/crit...) and facility (auth/cron/kern...).

	That would give us a lot of flexibility - we may want to listen to just critical errors coming from 'cron' but also all logs from 'kern'.

	To implement that in our logging system we need to learn about a more complex topic exchange.

	Topic exchange:
		Messages sent to a topic exchange can't have an arbitrary routing_key - it must be a list of words, delimited by dots. The words can be anything, but usually they specify some features connected to the message. A few valid routing key examples: "stock.usd.nyse", "nyse.vmw", "quick.orange.rabbit". There can be as many words in the routing key as you like, up to the limit of 255 bytes.

		The binding key must also be in the same form. The logic behind the topic exchange is similar to a direct one - a message sent with a particular routing key will be delivered to all the queues that are bound with a matching binding key. However there are two important special cases for binding keys:

			- * (star) can substitute for exactly one word
			- # (hash) can substitute for zero or more words

		Example:
			We're going to send messages which all describe animals. The messages will be sent with a routing key that consists of three words (two dots). The first word in the routing key will describe speed, second a colour and third a species: "<speed>.<colour>.<species>".

			We created three bindings: Q1 is bound with binding key "*.orange.*" and Q2 with "*.*.rabbit" and "lazy.#".

			These bindings can be summarised as:

				- Q1 is interested in all the orange animals.
				- Q2 wants to hear everything about rabbits, and everything about lazy animals.

			A message with a routing key set to "quick.orange.rabbit" will be delivered to both queues. Message "lazy.orange.elephant" also will go to both of them. On the other hand "quick.orange.fox" will only go to the first queue, and "lazy.brown.fox" only to the second. "lazy.pink.rabbit" will be delivered to the second queue only once, even though it matches two bindings. "quick.brown.fox" doesn't match any binding so it will be discarded.

			What happens if we break our contract and send a message with one or four words, like "orange" or "quick.orange.new.rabbit"? Well, these messages won't match any bindings and will be lost.

			On the other hand "lazy.orange.new.rabbit", even though it has four words, will match the last binding and will be delivered to the second queue.

		*!!! Topic exchange is powerful and can behave like other exchanges.

		When a queue is bound with "#" (hash) binding key - it will receive all the messages, regardless of the routing key - like in fanout exchange.

		When special characters "*" (star) and "#" (hash) aren't used in bindings, the topic exchange will behave just like a direct one.

		So, we can always use Topic Exchange.

RPC (request/reply pattern):
	We learned how to use Work Queues to distribute time-consuming tasks among multiple workers.

	But what if we need to run a function on a remote computer and wait for the result? Well, that's a different story. This pattern is commonly known as Remote Procedure Call or RPC.

	Client interface:
		To illustrate how an RPC service could be used we're going to create a simple client class. It's going to expose a method named CallAsync which sends an RPC request and blocks until the answer is received:

		A note on RPC
		Although RPC is a pretty common pattern in computing, it's often criticised. The problems arise when a programmer is not aware whether a function call is local or if it's a slow RPC. Confusions like that result in an unpredictable system and adds unnecessary complexity to debugging. Instead of simplifying software, misused RPC can result in unmaintainable spaghetti code.

		Bearing that in mind, consider the following advice:

			- Make sure it's obvious which function call is local and which is remote.
			- Document your system. Make the dependencies between components clear.
			- Handle error cases. How should the client react when the RPC server is down for a long time?
		
		When in doubt avoid RPC. If you can, you should use an asynchronous pipeline - instead of RPC-like blocking, results are asynchronously pushed to a next computation stage.

	Callback queue:
		In general doing RPC over RabbitMQ is easy. A client sends a request message and a server replies with a response message. In order to receive a response we need to send a 'callback' queue address with the request:

			var props = channel.CreateBasicProperties();
			props.ReplyTo = replyQueueName;

			var messageBytes = Encoding.UTF8.GetBytes(message);
			channel.BasicPublish(exchange: string.Empty,
			                     routingKey: "rpc_queue",
			                     basicProperties: props,
			                     body: messageBytes);

		Message Properties:
			The AMQP 0-9-1 protocol predefines a set of 14 properties that go with a message. Most of the properties are rarely used, with the exception of the following:

				- Persistent: Marks a message as persistent (with a value of true) or transient (any other value). Take a look at the second tutorial.
				- DeliveryMode: those familiar with the protocol may choose to use this property instead of Persistent. They control the same thing.
				- ContentType: Used to describe the mime-type of the encoding. For example for the often used JSON encoding it is a good practice to set this property to: application/json.
				- ReplyTo: Commonly used to name a callback queue.
				- CorrelationId: Useful to correlate RPC responses with requests.

	Correlation Id:
		In the method presented above we suggest creating a callback queue for every RPC request. That's pretty inefficient, but fortunately there is a better way - let's create a single callback queue per client.

		That raises a new issue, having received a response in that queue it's not clear to which request the response belongs. That's when the CorrelationId property is used. We're going to set it to a unique value for every request. Later, when we receive a message in the callback queue we'll look at this property, and based on that we'll be able to match a response with a request. If we see an unknown CorrelationId value, we may safely discard the message - it doesn't belong to our requests.

		You may ask, why should we ignore unknown messages in the callback queue, rather than failing with an error? It's due to a possibility of a race condition on the server side. Although unlikely, it is possible that the RPC server will die just after sending us the answer, but before sending an acknowledgment message for the request. If that happens, the restarted RPC server will process the request again. That's why on the client we must handle the duplicate responses gracefully, and the RPC should ideally be idempotent.

	Our RPC will work like this:

		- When the Client starts up, it creates an anonymous exclusive callback queue.
		- For an RPC request, the Client sends a message with two properties: ReplyTo, which is set to the callback queue and CorrelationId, which is set to a unique value for every request.
		- The request is sent to an rpc_queue queue.
		- The RPC worker (aka: server) is waiting for requests on that queue. When a request appears, it does the job and sends a message with the result back to the Client, using the queue from the ReplyTo property.
		- The client waits for data on the callback queue. When a message appears, it checks the CorrelationId property. If it matches the value from the request it returns the response to the application.

	Server:
		var factory = new ConnectionFactory { HostName = "localhost" };
		using var connection = factory.CreateConnection();
		using var channel = connection.CreateModel();

		channel.QueueDeclare(queue: "rpc_queue",
		                     durable: false,
		                     exclusive: false,
		                     autoDelete: false,
		                     arguments: null);
		channel.BasicQos(prefetchSize: 0, prefetchCount: 1, global: false);
		var consumer = new EventingBasicConsumer(channel);
		channel.BasicConsume(queue: "rpc_queue",
		                     autoAck: false,
		                     consumer: consumer);
		Console.WriteLine(" [x] Awaiting RPC requests");

		consumer.Received += (model, ea) =>
		{
		    string response = string.Empty;

		    var body = ea.Body.ToArray();
		    var props = ea.BasicProperties;
		    var replyProps = channel.CreateBasicProperties();
		    replyProps.CorrelationId = props.CorrelationId;

		    try
		    {
		        var message = Encoding.UTF8.GetString(body);
		        int n = int.Parse(message);
		        Console.WriteLine($" [.] Fib({message})");
		        response = Fib(n).ToString();
		    }
		    catch (Exception e)
		    {
		        Console.WriteLine($" [.] {e.Message}");
		        response = string.Empty;
		    }
		    finally
		    {
		        var responseBytes = Encoding.UTF8.GetBytes(response);
		        channel.BasicPublish(exchange: string.Empty,
		                             routingKey: props.ReplyTo,
		                             basicProperties: replyProps,
		                             body: responseBytes);
		        channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false);
		    }
		};

		The server code is rather straightforward:
			- As usual we start by establishing the connection, channel and declaring the queue.
			- We might want to run more than one server process. In order to spread the load equally over multiple servers we need to set the prefetchCount setting in channel.BasicQos.
			- We use BasicConsume to access the queue. Then we register a delivery handler in which we do the work and send the response back.

	Client:
		public class RpcClient : IDisposable
		{
		    private const string QUEUE_NAME = "rpc_queue";

		    private readonly IConnection connection;
		    private readonly IModel channel;
		    private readonly string replyQueueName;
		    private readonly ConcurrentDictionary<string, TaskCompletionSource<string>> callbackMapper = new();

		    public RpcClient()
		    {
		        var factory = new ConnectionFactory { HostName = "localhost" };

		        connection = factory.CreateConnection();
		        channel = connection.CreateModel();
		        // declare a server-named queue
		        replyQueueName = channel.QueueDeclare().QueueName;
		        var consumer = new EventingBasicConsumer(channel);
		        consumer.Received += (model, ea) =>
		        {
		            if (!callbackMapper.TryRemove(ea.BasicProperties.CorrelationId, out var tcs))
		                return;
		            var body = ea.Body.ToArray();
		            var response = Encoding.UTF8.GetString(body);
		            tcs.TrySetResult(response);
		        };

		        channel.BasicConsume(consumer: consumer,
		                             queue: replyQueueName,
		                             autoAck: true);
		    }

		    public Task<string> CallAsync(string message, CancellationToken cancellationToken = default)
		    {
		        IBasicProperties props = channel.CreateBasicProperties();
		        var correlationId = Guid.NewGuid().ToString();
		        props.CorrelationId = correlationId;
		        props.ReplyTo = replyQueueName;
		        var messageBytes = Encoding.UTF8.GetBytes(message);
		        var tcs = new TaskCompletionSource<string>();
		        callbackMapper.TryAdd(correlationId, tcs);

		        channel.BasicPublish(exchange: string.Empty,
		                             routingKey: QUEUE_NAME,
		                             basicProperties: props,
		                             body: messageBytes);

		        cancellationToken.Register(() => callbackMapper.TryRemove(correlationId, out _));
		        return tcs.Task;
		    }

		    public void Dispose()
		    {
		        connection.Close();
		    }
		}

		public class Rpc
		{
		    public static async Task Main(string[] args)
		    {
		        Console.WriteLine("RPC Client");
		        string n = args.Length > 0 ? args[0] : "30";
		        await InvokeAsync(n);

		        Console.WriteLine(" Press [enter] to exit.");
		        Console.ReadLine();
		    }

		    private static async Task InvokeAsync(string n)
		    {
		        using var rpcClient = new RpcClient();

		        Console.WriteLine(" [x] Requesting fib({0})", n);
		        var response = await rpcClient.CallAsync(n);
		        Console.WriteLine(" [.] Got '{0}'", response);
		    }
		}

		The client code is slightly more involved:

			- We establish a connection and channel and declare an exclusive 'callback' queue for replies.
			- We subscribe to the 'callback' queue, so that we can receive RPC responses.
			- Our Call method makes the actual RPC request.
			- Here, we first generate a unique CorrelationId number and save it to identify the appropriate response when it arrives.
			- Next, we publish the request message, with two properties: ReplyTo and CorrelationId.
			- At this point we can sit back and wait until the proper response arrives.
			- For every response message the client checks if the CorrelationId is the one we're looking for. If so, it saves the response.
			- Finally we return the response back to the user.

	The design presented here is not the only possible implementation of a RPC service, but it has some important advantages:

		- If the RPC server is too slow, you can scale up by just running another one. Try running a second RPCServer in a new console.
		- On the client side, the RPC requires sending and receiving only one message. No synchronous calls like QueueDeclare are required. As a result the RPC client needs only one network round trip for a single RPC request.

	Our code is still pretty simplistic and doesn't try to solve more complex (but important) problems, like:

		- How should the client react if there are no servers running?
		- Should a client have some kind of timeout for the RPC?
		- If the server malfunctions and raises an exception, should it be forwarded to the client?
		- Protecting against invalid incoming messages (eg checking bounds, type) before processing.

Publisher Confirms:
	Publisher confirms are a RabbitMQ extension to implement reliable publishing. When publisher confirms are enabled on a channel, messages the client publishes are confirmed asynchronously by the broker, meaning they have been taken care of on the server side.

	Enabling Publisher Confirms on a Channel:
		Publisher confirms are a RabbitMQ extension to the AMQP 0.9.1 protocol, so they are not enabled by default. Publisher confirms are enabled at the channel level with the ConfirmSelect method:

			var channel = connection.CreateModel();
			channel.ConfirmSelect();

	Strategy #1: Publishing Messages Individually:
		Let's start with the simplest approach to publishing with confirms, that is, publishing a message and waiting synchronously for its confirmation:

			while (ThereAreMessagesToPublish())
			{
			    byte[] body = ...;
			    IBasicProperties properties = ...;
			    channel.BasicPublish(exchange, queue, properties, body);
			    // uses a 5 second timeout
			    channel.WaitForConfirmsOrDie(TimeSpan.FromSeconds(5));
			}

		In the previous example we publish a message as usual and wait for its confirmation with the Channel#WaitForConfirmsOrDie(TimeSpan) method. The method returns as soon as the message has been confirmed. If the message is not confirmed within the timeout or if it is nack-ed (meaning the broker could not take care of it for some reason), the method will throw an exception. The handling of the exception usually consists in logging an error message and/or retrying to send the message.

		Different client libraries have different ways to synchronously deal with publisher confirms, so make sure to read carefully the documentation of the client you are using.

		This technique is very straightforward but also has a major drawback: it significantly slows down publishing, as the confirmation of a message blocks the publishing of all subsequent messages. This approach is not going to deliver throughput of more than a few hundreds of published messages per second. Nevertheless, this can be good enough for some applications.

		We mentioned at the beginning that the broker confirms published messages asynchronously but in the first example the code waits synchronously until the message is confirmed. The client actually receives confirms asynchronously and unblocks the call to WaitForConfirmsOrDie accordingly. Think of WaitForConfirmsOrDie as a synchronous helper which relies on asynchronous notifications under the hood.

	Strategy #2: Publishing Messages in Batches:
		To improve upon our previous example, we can publish a batch of messages and wait for this whole batch to be confirmed. The following example uses a batch of 100:

			var batchSize = 100;
			var outstandingMessageCount = 0;
			while (ThereAreMessagesToPublish())
			{
			    byte[] body = ...;
			    IBasicProperties properties = ...;
			    channel.BasicPublish(exchange, queue, properties, body);
			    outstandingMessageCount++;
			    if (outstandingMessageCount == batchSize)
			    {
			        channel.WaitForConfirmsOrDie(TimeSpan.FromSeconds(5));
			        outstandingMessageCount = 0;
			    }
			}
			if (outstandingMessageCount > 0)
			{
			    channel.WaitForConfirmsOrDie(TimeSpan.FromSeconds(5));
			}

		Waiting for a batch of messages to be confirmed improves throughput drastically over waiting for a confirm for individual message (up to 20-30 times with a remote RabbitMQ node). One drawback is that we do not know exactly what went wrong in case of failure, so we may have to keep a whole batch in memory to log something meaningful or to re-publish the messages. And this solution is still synchronous, so it blocks the publishing of messages.

	Strategy #3: Handling Publisher Confirms Asynchronously:
		The broker confirms published messages asynchronously, one just needs to register a callback on the client to be notified of these confirms:

			var channel = connection.CreateModel();
			channel.ConfirmSelect();
			channel.BasicAcks += (sender, ea) =>
			{
			  // code when message is confirmed
			};
			channel.BasicNacks += (sender, ea) =>
			{
			  //code when message is nack-ed
			};

		There are 2 callbacks: one for confirmed messages and one for nack-ed messages (messages that can be considered lost by the broker). Both callbacks have a corresponding EventArgs parameter (ea) containing a:

			- delivery tag: the sequence number identifying the confirmed or nack-ed message. We will see shortly how to correlate it with the published message.
			- multiple: this is a boolean value. If false, only one message is confirmed/nack-ed, if true, all messages with a lower or equal sequence number are confirmed/nack-ed.
		
		The sequence number can be obtained with Channel#NextPublishSeqNo before publishing:

			var sequenceNumber = channel.NextPublishSeqNo;
			channel.BasicPublish(exchange, queue, properties, body);

		A simple way to correlate messages with sequence number consists in using a dictionary. Let's assume we want to publish strings because they are easy to turn into an array of bytes for publishing. Here is a code sample that uses a dictionary to correlate the publishing sequence number with the string body of the message:

			var outstandingConfirms = new ConcurrentDictionary<ulong, string>();
			// ... code for confirm callbacks will come later
			var body = "...";
			outstandingConfirms.TryAdd(channel.NextPublishSeqNo, body);
			channel.BasicPublish(exchange, queue, properties, Encoding.UTF8.GetBytes(body));

		The publishing code now tracks outbound messages with a dictionary. We need to clean this dictionary when confirms arrive and do something like logging a warning when messages are nack-ed:

			var outstandingConfirms = new ConcurrentDictionary<ulong, string>();

			void CleanOutstandingConfirms(ulong sequenceNumber, bool multiple)
			{
			    if (multiple)
			    {
			        var confirmed = outstandingConfirms.Where(k => k.Key <= sequenceNumber);
			        foreach (var entry in confirmed)
			        {
			            outstandingConfirms.TryRemove(entry.Key, out _);
			        }
			    }
			    else
			    {
			        outstandingConfirms.TryRemove(sequenceNumber, out _);
			    }
			}

			channel.BasicAcks += (sender, ea) => CleanOutstandingConfirms(ea.DeliveryTag, ea.Multiple);
			channel.BasicNacks += (sender, ea) =>
			{
			    outstandingConfirms.TryGetValue(ea.DeliveryTag, out string body);
			    Console.WriteLine($"Message with body {body} has been nack-ed. Sequence number: {ea.DeliveryTag}, multiple: {ea.Multiple}");
			    CleanOutstandingConfirms(ea.DeliveryTag, ea.Multiple);
			};

			// ... publishing code

		The previous sample contains a callback that cleans the dictionary when confirms arrive. Note this callback handles both single and multiple confirms. This callback is used when confirms arrive (Channel#BasicAcks). The callback for nack-ed messages retrieves the message body and issues a warning. It then re-uses the previous callback to clean the dictionary of outstanding confirms (whether messages are confirmed or nack-ed, their corresponding entries in the dictionary must be removed.)

		How to Track Outstanding Confirms?
			Our samples use a ConcurrentDictionary to track outstanding confirms. This data structure is convenient for several reasons. It allows to easily correlate a sequence number with a message (whatever the message data is) and to easily clean the entries up to a given sequence id (to handle multiple confirms/nacks). At last, it supports concurrent access, because confirm callbacks are called in a thread owned by the client library, which should be kept different from the publishing thread.

			There are other ways to track outstanding confirms than with a sophisticated dictionary implementation, like using a simple concurrent hash table and a variable to track the lower bound of the publishing sequence, but they are usually more involved and do not belong to a tutorial.

		To sum up, handling publisher confirms asynchronously usually requires the following steps:

			- provide a way to correlate the publishing sequence number with a message.
			- register confirm listeners on the channel to be notified when publisher acks/nacks arrive to perform the appropriate actions, like logging or re-publishing a nack-ed message. The sequence-number-to-message correlation mechanism may also require some cleaning during this step.
			- track the publishing sequence number before publishing a message

		Re-publishing nack-ed Messages?
			It can be tempting to re-publish a nack-ed message from the corresponding callback but this should be avoided, as confirm callbacks are dispatched in an I/O thread where channels are not supposed to do operations. A better solution consists in enqueuing the message in an in-memory queue which is polled by a publishing thread. A class like ConcurrentQueue would be a good candidate to transmit messages between the confirm callbacks and a publishing thread.

	Summary:
		Making sure published messages made it to the broker can be essential in some applications. Publisher confirms are a RabbitMQ feature that helps to meet this requirement. Publisher confirms are asynchronous in nature but it is also possible to handle them synchronously. There is no definitive way to implement publisher confirms, this usually comes down to the constraints in the application and in the overall system. Typical techniques are:

			- publishing messages individually, waiting for the confirmation synchronously: simple, but very limited throughput.
			- publishing messages in batch, waiting for the confirmation synchronously for a batch: simple, reasonable throughput, but hard to reason about when something goes wrong.
			- asynchronous handling: best performance and use of resources, good control in case of error, but can be involved to implement correctly.
